---
title: "Spaceship Titanic survivorship"
author: "Drew Clayson"
format: html
editor: visual
---

## Introduction

Welcome to the year 2912, where your data science skills are needed to solve a cosmic mystery. We've received a transmission from four lightyears away and things aren't looking good.

The *Spaceship Titanic* was an interstellar passenger liner launched a month ago. With almost 13,000 passengers on board, the vessel set out on its maiden voyage transporting emigrants from our solar system to three newly habitable exoplanets orbiting nearby stars.

While rounding Alpha Centauri en route to its first destination---the torrid 55 Cancri E---the unwary *Spaceship Titanic* collided with a spacetime anomaly hidden within a dust cloud. Sadly, it met a similar fate as its namesake from 1000 years before. Though the ship stayed intact, almost half of the passengers were transported to an alternate dimension!

To help rescue crews and retrieve the lost passengers, you are challenged to predict which passengers were transported by the anomaly using records recovered from the spaceship's damaged computer system.

## Initial imports

I need to load all necessary libraries

```{r}
library(GGally) # pairs plots
library(gam) # gam models
library(leaps) # regression subsets
library(tree) # trees
library(randomForest) # random forest
library(gbm) # boosting
library(glmnet) # Ridge/lasso
library(ISLR)
library(tidyverse)
library(missForest)
```

I will begin by importing all the necessary information and imputing data. The primary reason for imputation is because the test set of data also has missing values in it. This is generally problematic because most modern regression and tree techniques don't work well with missing data. We can't throw them out because they are in the test set as well. So imputation must be key. Generally there are a few options for imputation. LOCF and similar are simple, and just carry the same data forward, which may work fine for some variables but not others. In all honesty, LOCF would be a very reasonable choice here because it works fine with both numeric and string data. KNN is certainly not a good imputation choice here. Since it is not very robust to outliers, it may be a poor method given the distribution of the data itself with most numeric info being 0, and a few larger numbers, you'd run a considerable risk. Furthermore, KNN imputation won't work with factor data, which is also missing in parts. So that leaves us with missing forests. Using random forests to impute information is much more robust than KNN, and it works quite well with both numeric and factored data. The biggest tradeoff is computational power. It takes a lot more time and power to run a missing forest. I chose missing forest for this project, as it makes the most sense for the data at hand.

```{r}
train <- read.csv("train.csv")
test <- read.csv("test.csv")
train[,14] <-  1 * (train[,14] == "True")
CryosleepYes <- which(train$CryoSleep != "")
train[CryosleepYes, 3] <- 1 * (train[CryosleepYes, 3] == "True")
VIPYes <- which(train$VIP != "")
train[VIPYes, 7] <- 1 * (train[VIPYes, 7] == "True")
CabinYes <- train$Cabin != ""
SplitMat <- matrix(unlist(strsplit(train$Cabin, split = "/")),ncol=3,byrow=T)
train[c('Deck','Num','Side')] <- ""
train[c('Deck','Num','Side')][CabinYes,] <- SplitMat[,1:3]
train <- train[-c(1, 4, 13)]
train <- train %>% mutate_all(~replace(., .=="", NA))
train <- train %>% mutate_at(vars(CryoSleep, VIP, Destination, HomePlanet, Deck, Side, Transported), factor)
train$Num <- as.numeric(train$Num)
Fixed_Train <- missForest(train)
Filledtrain <- Fixed_Train$ximp

# Adjust Test Set Data

CryosleepYes <- which(test$CryoSleep != "")
test[CryosleepYes, 3] <- 1 * (test[CryosleepYes, 3] == "True")
VIPYes <- which(test$VIP != "")
test[VIPYes, 7] <- 1 * (test[VIPYes, 7] == "True")
CabinYes <- test$Cabin != ""
SplitMat <- matrix(unlist(strsplit(test$Cabin, split = "/")),ncol=3,byrow=T)
test[c('Deck','Num','Side')] <- ""
test[c('Deck','Num','Side')][CabinYes,] <- SplitMat[,1:3]
test <- test[-c(1, 4, 13)]
test <- test %>% mutate_all(~replace(., .=="", NA))
test <- test %>% mutate_at(vars(CryoSleep, VIP, Destination, HomePlanet, Deck, Side), factor)
test$Num <- as.numeric(test$Num)
Fixed_Test <- missForest(test)
Filledtest <- Fixed_Test$ximp

```

# Imputation of missing values

# Visualization and Summary

I must begin the analysis by performing some visualization of the data

```{r}
Filledtrain %>% group_by(VIP) %>% summarise(sum(Transported == 1) / n())
Filledtrain %>% group_by(HomePlanet) %>% summarise(sum(Transported == 1) / n())
Filledtrain %>% group_by(CryoSleep) %>% summarise(sum(Transported == 1) / n())
Filledtrain %>% group_by(Side) %>% summarise(sum(Transported == 1) / n())
Filledtrain %>% group_by(Deck) %>% summarise(sum(Transported == 1) / n())
ggplot(data = Filledtrain, mapping = aes(x = RoomService,y = FoodCourt, color = Transported)) +
  geom_point()
```

VIPs had a lower probability of being transported. Earthlings had a lower probability and Europans had a higher one. Tose in cryosleep had a much higher probability of being transported. Those on the starboard side were more likely to be transported as well as those on decks b and C.

# Elastic Nets

## Ridge Regression

I will begin by performing multiple elastic nets. Ridge regression comes when $\alpha = 0$ and LASSO regression comes from $\alpha = 1$. An elastic net can result in $\alpha$ between 0 and 1. To find values of $\alpha$ I need to generate fold ids.

```{r}
X <- model.matrix(Transported ~ ., data = Filledtrain)
Transported <- Filledtrain$Transported
Foldid <- sample(1:10, dim(X)[1], replace = TRUE)
lambdas <- 10^(seq( -6,2, by = 0.1))
RidgeOut <- cv.glmnet(x = X, y = Transported,family = "binomial", alpha = 0, lambda = lambdas, foldid = Foldid)
RidgeDev <- deviance(RidgeOut$glmnet.fit)[RidgeOut$glmnet.fit$lambda == RidgeOut$lambda.min]
plot(RidgeOut)
```

## LASSO regression

```{r}

LassoOut <- cv.glmnet(x = X, y = Transported,family = "binomial", alpha = 1, lambda = lambdas, foldid = Foldid)
LassoDev <- deviance(LassoOut$glmnet.fit)[which(LassoOut$glmnet.fit$lambda == LassoOut$lambda.min)]
plot(LassoOut)


```

## Elastic Net

This will include lasso and ridge models to more easily compare the deviances of each model. What I've found is that the lowest deviance tends to be one of the elastic nets rather than the pure ridge or pure lasso models.

```{r}
CV <- data.frame(Alphas = seq(0,1, by = 0.1), LambdaMin = NA, Deviance = NA)
j <- 1
par(mfrow = c(3,3))
for (i in CV$Alphas){
  eNetOut <- cv.glmnet(x = X, y = Transported,family = "binomial", alpha = i, lambda = lambdas, foldid = Foldid)
  plot(eNetOut)
  CV$LambdaMin[j] <- eNetOut$lambda.min
  CV$Deviance[j] <- deviance(eNetOut$glmnet.fit)[which(eNetOut$glmnet.fit$lambda == eNetOut$lambda.min)]
  j <- j+1
}
Opt <- which(c(CV$Deviance, LassoDev, RidgeDev) == min(c(CV$Deviance, LassoDev, RidgeDev)))

```

It appears

# Trees

## Single Tree

```{r}
n <- dim(Filledtrain)[1]
tr_index <- sample(1:n, size = 7000, replace = F)
train_x <- Filledtrain[tr_index, ]
val_x <- Filledtrain[-tr_index, ]

dtree <- tree(Transported ~ ., data = train_x, split = "deviance")
summary(dtree)
plot(dtree, type = "uniform")
text(dtree, pretty = 0, cex = 0.3)

preds <- predict(dtree, val_x, type = "class")
mean(preds == val_x$Transported)
```

The tree model generated did not have a particularly large number of leaves involved. In theory I could prune according to misclassifications, but given the already small size, it might not be necessary.

## Boosting

```{r}
train_x2 <- train_x
train_x2$Transported <- train_x2$Transported == 1
gbmOut <- gbm(Transported ~ ., distribution = "bernoulli", n.trees = 1000,
              interaction.depth = 1, data = train_x2, shrinkage = 0.01)
phats <- predict(gbmOut, val_x, type = "response")
preds <- (phats > 0.5) * 1
mean(preds == val_x$Transported)
```

The boosted tree is only marginally better than the basic tree when looking at the accuracy on the validation set.

## Random Forest and Bagging

```{r}
p <- dim(train_x)[2] - 1
baggedTrees <- randomForest(Transported ~ ., mtry = p, data = train_x)
preds <- predict(baggedTrees, val_x, type = "response")
mean(preds == val_x$Transported)

rfTrees <- randomForest(Transported ~ ., mtry = 4, data = train_x)
preds <- predict(rfTrees, val_x, type = "response")
mean(preds == val_x$Transported)
```

The bagged trees performed better than both the original, and the boosted tree models. However, so far the best performance has been with the random forest model produced above. I will see how each of the optimal models of each kind does against the true testing data.

```{r}
# Final Predictions
submission <- read.csv("sample_submission.csv")
eNetFinal <- glmnet(x = X, y = Transported,family = "binomial", alpha = CV$Alphas[Opt], lambda = CV$LambdaMin[Opt])
newX <- model.matrix(~.,Filledtest)
preds <- predict(eNetFinal, newX, type = "response")
preds <- (preds >= 0.5)
submission$Transported[preds] <- "True"
write.csv(submission, "eNetSubmission.csv",row.names = FALSE)
submission$Transported <- "False"
preds <- predict(dtree, Filledtest, type = "class")
submission$Transported[preds == 1] <- "True"
write.csv(submission, "TreeSubmission.csv",row.names = FALSE)
submission$Transported <- "False"
preds <- predict(gbmOut, Filledtest, type = "response")
submission$Transported[preds >= 0.5] <- "True"
write.csv(submission, "GBMSubmission.csv",row.names = FALSE)
submission$Transported <- "False"
preds <- predict(baggedTrees, Filledtest, type = "response")
submission$Transported[preds == 1] <- "True"
write.csv(submission, "BaggedSubmission.csv",row.names = FALSE)
submission$Transported <- "False"
preds <- predict(rfTrees, Filledtest, type = "response")
submission$Transported[preds == 1] <- "True"
write.csv(submission, "
RandomForestSubmission.csv", row.names = FALSE)
```

In the end, my first submission of the elastic net turned out to be the best option.

```{r}
train <- read.csv("train.csv")
test <- read.csv("test.csv")
train[,14] <-  1 * (train[,14] == "True")
CryosleepYes <- which(train$CryoSleep != "")
train[CryosleepYes, 3] <- 1 * (train[CryosleepYes, 3] == "True")
VIPYes <- which(train$VIP != "")
train[VIPYes, 7] <- 1 * (train[VIPYes, 7] == "True")
CabinYes <- train$Cabin != ""
SplitMat <- matrix(unlist(strsplit(train$Cabin, split = "/")),ncol=3,byrow=T)
train[c('Deck','Num','Side')] <- ""
train[c('Deck','Num','Side')][CabinYes,] <- SplitMat[,1:3]
train <- train[-c(4, 13)]
train <- train %>% mutate_all(~replace(., .=="", NA))
train <- train %>% mutate_at(vars(CryoSleep, VIP, Destination, HomePlanet, Deck, Side, Transported), factor)
train$Num <- as.numeric(train$Num)
CryosleepYes <- which(test$CryoSleep != "")
test[CryosleepYes, 3] <- 1 * (test[CryosleepYes, 3] == "True")
VIPYes <- which(test$VIP != "")
test[VIPYes, 7] <- 1 * (test[VIPYes, 7] == "True")
CabinYes <- test$Cabin != ""
SplitMat <- matrix(unlist(strsplit(test$Cabin, split = "/")),ncol=3,byrow=T)
test[c('Deck','Num','Side')] <- ""
test[c('Deck','Num','Side')][CabinYes,] <- SplitMat[,1:3]
test <- test[-c(4, 13)]
test <- test %>% mutate_all(~replace(., .=="", NA))
test <- test %>% mutate_at(vars(CryoSleep, VIP, Destination, HomePlanet, Deck, Side), factor)
test$Num <- as.numeric(test$Num)
test$Transported <- NA

Total <- rbind(train, test)
y <- strsplit(as.character(Total$PassengerId), split = "_")
Total$ResId <- t(as.data.frame(y))[,1]
Total$Ind <- t(as.data.frame(y))[,2]
Total <- Total %>% mutate_at(vars(ResId, Ind), as.numeric)

Total <- Total %>% arrange(ResId, Ind)
Total <- Total[-1]

mf_Total <- missForest(Total, maxiter = 30, ntree = 1000)
indexes <- which(is.na(Total$Transported))
submission$Transported <- "False"
submission$Transported[mf_Total$ximp$Transported[indexes] == 1] <- "True"
write.csv(submission, "MissingForestSubmission.csv", row.names = FALSE)

```

This method was ineffective.
